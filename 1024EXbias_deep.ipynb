{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%run deepCNN.ipynb\n",
    "%run train_model.ipynb\n",
    "%run data_handler.ipynb\n",
    "\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=None)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#This is my 5-fold validation loop :D\n",
    "def cross_validation_loop(bias, LR = 0.001, epochs = 50, batch_size = 4):\n",
    "    filename = \"results/1024bias_deep.txt\"\n",
    "\n",
    "    fil = open(filename, \"a\")\n",
    "    fil.write(\"Experiment done on model {0}. \\n Learning rate: {1} \\n Optimizer: {2} \\n Loss function: {3} \\n Epochs: {6}, Batch size: {7}, Bias: {8}\\n Experiments run on {4} interval with frequency {5} Hz on the data.\"\n",
    "    .format(\"deepCNN\", LR, \"Adam\", \"NLLLoss\", \"full\", 1024, epochs, batch_size, bias))\n",
    "    fil.close()\n",
    "\n",
    "    saved_models = []\n",
    "\n",
    "    for subject_nr in range(1,11):\n",
    "        subject_models = []\n",
    "        print(\"Loading subject \", subject_nr)\n",
    "        data, description = load_subject_non_downsampled(subject_nr)\n",
    "        data, description = get_innerspeech(data, description)\n",
    "        # data_interval = extract_action_interval(data, hz = 254)\n",
    "        labels = extract_labels(description)\n",
    "\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        test_accuracies = []\n",
    "\n",
    "        i = 0\n",
    "        for train_index, test_index in kf.split(data, labels, labels):\n",
    "            print(\"### Fold {0} ###\".format(i))\n",
    "\n",
    "            # New model\n",
    "            model = DeepCNN(hz = 1024, interval = \"full\", bias = bias).float().to(device)\n",
    "            loss_func = nn.NLLLoss()\n",
    "            op = optim.Adam(params = model.parameters(), lr = LR)\n",
    "\n",
    "            # Choose train+val data/labels\n",
    "            train_da=data[train_index]\n",
    "            train_la=labels[train_index]\n",
    "            # Choose test data/labels\n",
    "            test_data=data[test_index]\n",
    "            test_labels=labels[test_index]\n",
    "\n",
    "            # Split train into train and val\n",
    "            train_data, val_data, train_labels, val_labels = train_test_split(train_da, train_la, test_size = 0.25, random_state = None, shuffle = True, stratify = train_la)\n",
    "            train_data, val_data, test_data, train_labels, val_labels, test_labels = to_device(train_data, val_data, test_data, train_labels, val_labels, test_labels, device)\n",
    "            # Train loop\n",
    "            train_model(model, train_data = train_data, train_labels = train_labels, val_data = val_data, val_labels = val_labels, \n",
    "                        epochs = epochs, batch_size = batch_size, loss_func = loss_func, optimizer = op)\n",
    "            # Save model\n",
    "            subject_models.append(model)\n",
    "            i += 1\n",
    "            # Save accuracies\n",
    "            train_accuracies.append(accuracy_check(model, train_data, train_labels))\n",
    "            val_accuracies.append(accuracy_check(model, val_data, val_labels))\n",
    "            test_accuracies.append(accuracy_check(model, test_data, test_labels))\n",
    "            cf = get_conf_matrix(model, test_data, test_labels)\n",
    "            plt.show(sns.heatmap(cf, annot=True))\n",
    "        \n",
    "        saved_models.append(subject_models)\n",
    "        # Write results for subject to file\n",
    "        fil = open(filename, \"a\")\n",
    "        fil.write(\"\\n\\nResults for subject {0}.\\n\".format(subject_nr))\n",
    "        fil.write(\"Train accuracies from 5 folds:\\n\")\n",
    "        for acc in train_accuracies:\n",
    "            fil.write(\"{0}, \".format(acc))\n",
    "        fil.write(\"\\n\")\n",
    "        fil.write(\"Validation accuracies from 5 folds:\\n\")\n",
    "        for acc in val_accuracies:\n",
    "            fil.write(\"{0}, \".format(acc))\n",
    "        fil.write(\"\\n\")\n",
    "        fil.write(\"Test accuracies from 5 folds:\\n\")\n",
    "        for acc in test_accuracies:\n",
    "            fil.write(\"{0}, \".format(acc))\n",
    "        fil.write(\"\\n\")\n",
    "\n",
    "        fil.write(\"Avg train acc: {0}, Avg validation acc: {1}, Avg test acc: {2}, \".format(sum(train_accuracies)/5, sum(val_accuracies)/5, sum(test_accuracies)/5))\n",
    "        fil.write(\"\\n\\n#####################################\\n\\n\")\n",
    "        fil.close()\n",
    "    return saved_models\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models1 = cross_validation_loop(bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models1 = cross_validation_loop(bias=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
