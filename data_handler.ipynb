{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99, 99, 99, 99] \n",
      " [13, 13, 14, 14] \n",
      " [13, 13, 12, 12]\n",
      "25.0 %  25.0 %  25.0 %  25.0 % \n",
      "24.074074074074073 %  24.074074074074073 %  25.925925925925924 %  25.925925925925924 % \n",
      "26.0 %  26.0 %  24.0 %  24.0 % \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Inner_Speech_Dataset.Python_Processing.Data_extractions import  Extract_data_from_subject\n",
    "\n",
    "# Load all data for subject\n",
    "def load_subject(subject_nr):\n",
    "    datatype = \"EEG\"\n",
    "    root_dir = \"../dataset\"\n",
    "\n",
    "    data, description = Extract_data_from_subject(root_dir, subject_nr, datatype)\n",
    "    return data, description\n",
    "\n",
    "# Extract labels from the description\n",
    "def extract_labels(desc):\n",
    "    return desc[:,1]\n",
    "\n",
    "\n",
    "# Test when extracting only the action interval\n",
    "def extract_action_interval(data):\n",
    "    return data[:,:,254:890]\n",
    "\n",
    "def split_data(data, labels):\n",
    "    trainv_data, test_data, trainv_labels, test_labels = train_test_split(data, labels, test_size = 0.1, random_state = 1, shuffle = True, stratify = labels)# 10% test data\n",
    "    train_data, val_data, train_labels, val_labels = train_test_split(trainv_data, trainv_labels, test_size = 0.12, random_state = 1, shuffle = True, stratify = trainv_labels) # Approx 10% val data\n",
    "\n",
    "    return train_data, val_data, test_data, train_labels, val_labels, test_labels\n",
    "\n",
    "######### Check correct distr of split ################\n",
    "def split_info(train_data, val_data, test_data, train_labels, val_labels, test_labels):\n",
    "    t = [0,0,0,0]\n",
    "    v = [0,0,0,0]\n",
    "    te = [0,0,0,0]\n",
    "\n",
    "    for l in train_labels:\n",
    "        t[l] +=1\n",
    "\n",
    "    for l in val_labels:\n",
    "        v[l] +=1\n",
    "\n",
    "    for l in test_labels:\n",
    "        te[l] +=1\n",
    "\n",
    "    print(t,\"\\n\", v, \"\\n\", te)\n",
    "\n",
    "    print(t[0]/len(train_data)*100, \"% \", t[1]/len(train_data)*100, \"% \",t[2]/len(train_data)*100, \"% \",t[3]/len(train_data)*100, \"% \")\n",
    "    print(v[0]/len(val_data)*100, \"% \", v[1]/len(val_data)*100, \"% \",v[2]/len(val_data)*100, \"% \",v[3]/len(val_data)*100, \"% \")\n",
    "    print(te[0]/len(test_data)*100, \"% \", te[1]/len(test_data)*100, \"% \",te[2]/len(test_data)*100, \"% \",te[3]/len(test_data)*100, \"% \")\n",
    "\n",
    "\n",
    "# Load, extract and split data\n",
    "#data, description = load_subject(1)\n",
    "#labels = extract_labels(description)\n",
    "#new_data = extract_action_interval(data)\n",
    "#print(new_data.shape)\n",
    "\n",
    "\n",
    "#train_data, val_data, test_data, train_labels, val_labels, test_labels = split_data(data, labels)\n",
    "\n",
    "\n",
    "#split_info(train_data, val_data, test_data, train_labels, val_labels, test_labels)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "776ed16b974eb4051a720ba098885814801e01a01a8691ffdcc6d2fcef736aab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('inner_speech': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
