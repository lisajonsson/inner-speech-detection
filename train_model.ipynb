{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for training with validation\n",
    "TODO: Implement early stopping with patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_data, train_labels, val_data, val_labels, epochs, batch_size, loss_func, optimizer):\n",
    "    \n",
    "    print(\"Epoch\\t train loss\\t validation loss\")\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10000 # bad value for dis, validation loss comparison\n",
    "\n",
    "    for epoch in range(epochs):        \n",
    "        epoch_train_loss = 0\n",
    "        epoch_val_loss = 0\n",
    "        model.train() # Set model to train mode\n",
    "        \n",
    "        for i in range(len(train_data)//batch_size): # BATCH SIZE MUST BE EVEN DIVIDER OF DATA LEN, otherwise we miss stuff here\n",
    "            start = i*batch_size\n",
    "            end = (i+1)*batch_size\n",
    "\n",
    "            train_inputs = train_data[start:end]\n",
    "            train_truth = train_labels[start:end]\n",
    "            train_outputs = model(train_inputs)\n",
    "\n",
    "            loss = loss_func(train_outputs, train_truth)\n",
    "            \n",
    "            #print(\"LOSS: \", loss)\n",
    "            epoch_train_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        model.eval() # Set model to evaluation mode\n",
    "\n",
    "        #val_inputs = torch.tensor(val_data, dtype = torch.float32, device = \"cuda:0\")\n",
    "        #val_truth = torch.tensor(val_labels, dtype = torch.long, device = \"cuda:0\")\n",
    "        val_outputs = model(val_data)\n",
    "        val_loss = loss_func(val_outputs, val_labels)\n",
    "        epoch_val_loss += val_loss\n",
    "\n",
    "        # Check for new best model, this should be on val_data instead\n",
    "        if epoch_val_loss < best_loss:\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print(epoch, \"\\t \", epoch_train_loss.item()/(len(train_data)//batch_size), \"\\t\", epoch_val_loss.item())\n",
    "\n",
    "    model.load_state_dict(best_model) # Set model to best performing one.\n",
    "    \n",
    "\n",
    "\n",
    "# TODO: Run on cuda.\n",
    "# TODO: Add validation data and labels to train_model method params [DONE]\n",
    "# TODO: Implement early stopping.\n",
    "# TODO: Graphing of train and val loss, save train and val loss & perhaps accuracy to plot later.\n",
    "\n",
    "\n",
    "def accuracy_check(network, data, labels):\n",
    "    network.eval()\n",
    "\n",
    "    # Accuracy check\n",
    "    r = network(data)\n",
    "    p = torch.max(r,1)[1]\n",
    "    c = torch.sum(p == labels)\n",
    "    print(\"ACCURACY:\", c.item()/len(p))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "776ed16b974eb4051a720ba098885814801e01a01a8691ffdcc6d2fcef736aab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('inner_speech': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
